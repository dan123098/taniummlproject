{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39831a93",
   "metadata": {},
   "source": [
    "# Predicting Employee Retention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c7523f",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "\n",
    "In this section of the model, we are preparing the given data in a format the model can understand. NumPy allows support for creating multi-demention arrays and matrices, as well as other mathematical functions to operate on these structures. We will be using the Pandas library in order to access data analysis and manipulation tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "95107a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/mwitiderrick/kerasDO/master/HR_comma_sep.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac3ebf",
   "metadata": {},
   "source": [
    ".head() allows us to preview the first five records of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "76394ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>department</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years department  \\\n",
       "0                   3              0     1                      0      sales   \n",
       "1                   6              0     1                      0      sales   \n",
       "2                   4              0     1                      0      sales   \n",
       "3                   5              0     1                      0      sales   \n",
       "4                   3              0     1                      0      sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a1b8a9",
   "metadata": {},
   "source": [
    "# Creating Dummy Variables \n",
    "The dummy variable trap is a situation whereby two or more variables are highly correlated. This leads to your model performing poorly. You, therefore, drop one dummy variable to always remain with N-1 dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "7ff2c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['department','salary']\n",
    "df_final = pd.get_dummies(df,columns=feats,drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e6a6f",
   "metadata": {},
   "source": [
    "# Separating Training and Testing Datasets \n",
    "\n",
    "We implement this split in the dataset so the model you build doesnâ€™t have access to the testing data during the training process. This ensures that the model learns only from the training data, and you can then test its performance with the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "98cf651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "0d56b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final.drop(['left'],axis=1).values\n",
    "y = df_final['left'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "ababfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cd9343",
   "metadata": {},
   "source": [
    "# Transforming/Scaling the Data\n",
    "\n",
    "It is important to scale the dataset in order to make the computations more efficient. The code below scales the values such that we will have a mean of 0 and a standard deviation of 1. This step is crucial because we are comparing features that have different measurements  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "c83c0ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "68f868b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\home\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\home\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\home\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\home\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\home\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\home\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\home\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\home\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\home\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!$sys.executable -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a73fd7",
   "metadata": {},
   "source": [
    "# Building the Artificial Neural Network\n",
    "\n",
    "We will now implement Keras to build the deep learning model. Our model will have three layers: input, hidden, output. The input layer is the layer to which we pass the features of the dataset. The hidden layers perform the computations and pass the information to the output layer. The outer layer is the layer responsible for delivering the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "7e757ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "53dde281",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "3348a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(9, kernel_initializer = \"uniform\",activation = \"relu\", input_dim=18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "e5345c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(1, kernel_initializer = \"uniform\",activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "26e21ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e81c58",
   "metadata": {},
   "source": [
    "# Fitting Classifer into the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "ff552976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 1s 702us/step - loss: 0.4296 - accuracy: 0.7911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c500a73a0>"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411f12c",
   "metadata": {},
   "source": [
    "# Running Predictions on the Test Set\n",
    "\n",
    "We will now use the testing dataset to test our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "6960ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 479us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "a95d5a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caac0f9",
   "metadata": {},
   "source": [
    "# Checking the Confusion Matrix\n",
    "\n",
    "In this step we will be using a confusion matrix to check the number of correct and incorrect predictions. The confusion matrix will report the number of true positives, false positives, true negatives, and false negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "c3582cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3238,  157],\n",
       "       [ 653,  452]], dtype=int64)"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a426a",
   "metadata": {},
   "source": [
    "# Making a Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "c25674d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "new_pred = classifier.predict(sc.transform(np.array([[0,0.2,3., 28., 1., 0.,0.,0.,0., 0.,0.,0.,0.,0.,1.,0., 0.,1.]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "43b000a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred = (new_pred > 0.5)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "09747ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "new_pred = classifier.predict(sc.transform(np.array([[0.45,0.48 ,2., 245., 3., 0.,0.,0.,0., 0.,0.,0.,0.,0.,0,0., 0.,1.]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "607c43f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred = (new_pred > 0.5)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "f317d94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "new_pred = classifier.predict(sc.transform(np.array([[0.9,0.7 ,5., 240., 0. , 0.,0.,0.,0., 0.,0.,0.,0.,0.,1.,0., 0.,1.]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "b4003967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred = (new_pred > 0.5)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab8fe24",
   "metadata": {},
   "source": [
    "# Improving Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "246b43a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "2b256610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(9, kernel_initializer = \"uniform\", activation = \"relu\", input_dim=18))\n",
    "    classifier.add(Dense(1, kernel_initializer = \"uniform\", activation = \"sigmoid\"))\n",
    "    classifier.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "3020a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_19136\\128404206.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_fn = make_classifier, batch_size=10, nb_epoch=1)\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = make_classifier, batch_size=10, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "2d37267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(estimator = classifier,X = X_train,y = y_train,cv = 10,n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "e100cdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8141704022884368"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = accuracies.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "b1b72973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0031464708918996463"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance = accuracies.var()\n",
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b0716f",
   "metadata": {},
   "source": [
    "# Adding Dropout Regularization\n",
    "\n",
    "Predictive models are prone to a problem known as overfitting. This is a scenario whereby the model memorizes the results in the training set and isnâ€™t able to generalize on data that it hasnâ€™t seen. We counteract this by adding dropout regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "4901222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(9, kernel_initializer = \"uniform\", activation = \"relu\", input_dim=18))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "classifier.add(Dense(1, kernel_initializer = \"uniform\", activation = \"sigmoid\"))\n",
    "classifier.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9bfe67",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Grid search is a technique that you can use to experiment with different model parameters in order to obtain the ones that give you the best accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "592b3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def make_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(9, kernel_initializer = \"uniform\", activation = \"relu\", input_dim=18))\n",
    "    classifier.add(Dense(1, kernel_initializer = \"uniform\", activation = \"sigmoid\"))\n",
    "    classifier.compile(optimizer= optimizer,loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "4e10a539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Temp\\ipykernel_19136\\4215114608.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  classifier = KerasClassifier(build_fn = make_classifier)\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = make_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "fbf3faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size':[20,35],\n",
    "    'epochs':[2,3],\n",
    "    'optimizer':['adam','rmsprop']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "2a4499da",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=classifier,\n",
    "                           param_grid=params,\n",
    "                           scoring=\"accuracy\",\n",
    "                           cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "38619fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "263/263 [==============================] - 1s 714us/step - loss: 0.5608 - accuracy: 0.7689\n",
      "Epoch 2/2\n",
      "263/263 [==============================] - 0s 737us/step - loss: 0.4046 - accuracy: 0.7689\n",
      "165/165 [==============================] - 0s 494us/step\n",
      "Epoch 1/2\n",
      "263/263 [==============================] - 1s 695us/step - loss: 0.5870 - accuracy: 0.7577\n",
      "Epoch 2/2\n",
      "263/263 [==============================] - 0s 707us/step - loss: 0.3938 - accuracy: 0.8358\n",
      "165/165 [==============================] - 0s 494us/step\n",
      "Epoch 1/2\n",
      "263/263 [==============================] - 1s 661us/step - loss: 0.5917 - accuracy: 0.7680\n",
      "Epoch 2/2\n",
      "263/263 [==============================] - 0s 649us/step - loss: 0.4150 - accuracy: 0.8015\n",
      "165/165 [==============================] - 0s 476us/step\n",
      "Epoch 1/2\n",
      "263/263 [==============================] - 1s 684us/step - loss: 0.6002 - accuracy: 0.7608\n",
      "Epoch 2/2\n",
      "263/263 [==============================] - 0s 672us/step - loss: 0.4395 - accuracy: 0.7975\n",
      "165/165 [==============================] - 0s 500us/step\n",
      "Epoch 1/3\n",
      "263/263 [==============================] - 1s 714us/step - loss: 0.5688 - accuracy: 0.7683\n",
      "Epoch 2/3\n",
      "263/263 [==============================] - 0s 714us/step - loss: 0.4082 - accuracy: 0.7689\n",
      "Epoch 3/3\n",
      "263/263 [==============================] - 0s 722us/step - loss: 0.3682 - accuracy: 0.7689\n",
      "165/165 [==============================] - 0s 488us/step\n",
      "Epoch 1/3\n",
      "263/263 [==============================] - 1s 672us/step - loss: 0.5766 - accuracy: 0.7613\n",
      "Epoch 2/3\n",
      "263/263 [==============================] - 0s 691us/step - loss: 0.4244 - accuracy: 0.7613\n",
      "Epoch 3/3\n",
      "263/263 [==============================] - 0s 711us/step - loss: 0.3822 - accuracy: 0.7613\n",
      "165/165 [==============================] - 0s 470us/step\n",
      "Epoch 1/3\n",
      "263/263 [==============================] - 1s 657us/step - loss: 0.6078 - accuracy: 0.7716\n",
      "Epoch 2/3\n",
      "263/263 [==============================] - 0s 661us/step - loss: 0.4317 - accuracy: 0.8047\n",
      "Epoch 3/3\n",
      "263/263 [==============================] - 0s 680us/step - loss: 0.3401 - accuracy: 0.8390\n",
      "165/165 [==============================] - 0s 484us/step\n",
      "Epoch 1/3\n",
      "263/263 [==============================] - 1s 642us/step - loss: 0.5809 - accuracy: 0.7613\n",
      "Epoch 2/3\n",
      "263/263 [==============================] - 0s 631us/step - loss: 0.4427 - accuracy: 0.7613\n",
      "Epoch 3/3\n",
      "263/263 [==============================] - 0s 642us/step - loss: 0.4020 - accuracy: 0.7613\n",
      "165/165 [==============================] - 0s 464us/step\n",
      "Epoch 1/2\n",
      "150/150 [==============================] - 0s 692us/step - loss: 0.6285 - accuracy: 0.7672\n",
      "Epoch 2/2\n",
      "150/150 [==============================] - 0s 719us/step - loss: 0.4654 - accuracy: 0.7731\n",
      "165/165 [==============================] - 0s 476us/step\n",
      "Epoch 1/2\n",
      "150/150 [==============================] - 0s 645us/step - loss: 0.6324 - accuracy: 0.7592\n",
      "Epoch 2/2\n",
      "150/150 [==============================] - 0s 638us/step - loss: 0.4747 - accuracy: 0.7615\n",
      "165/165 [==============================] - 0s 458us/step\n",
      "Epoch 1/2\n",
      "150/150 [==============================] - 0s 692us/step - loss: 0.6300 - accuracy: 0.7695\n",
      "Epoch 2/2\n",
      "150/150 [==============================] - 0s 638us/step - loss: 0.4896 - accuracy: 0.7689\n",
      "165/165 [==============================] - 0s 476us/step\n",
      "Epoch 1/2\n",
      "150/150 [==============================] - 0s 640us/step - loss: 0.6414 - accuracy: 0.7575\n",
      "Epoch 2/2\n",
      "150/150 [==============================] - 0s 645us/step - loss: 0.5200 - accuracy: 0.7722\n",
      "165/165 [==============================] - 0s 458us/step\n",
      "Epoch 1/3\n",
      "150/150 [==============================] - 0s 712us/step - loss: 0.6398 - accuracy: 0.7560\n",
      "Epoch 2/3\n",
      "150/150 [==============================] - 0s 699us/step - loss: 0.4642 - accuracy: 0.7933\n",
      "Epoch 3/3\n",
      "150/150 [==============================] - 0s 719us/step - loss: 0.3746 - accuracy: 0.8053\n",
      "165/165 [==============================] - 0s 482us/step\n",
      "Epoch 1/3\n",
      "150/150 [==============================] - 0s 685us/step - loss: 0.6370 - accuracy: 0.7598\n",
      "Epoch 2/3\n",
      "150/150 [==============================] - 0s 665us/step - loss: 0.4861 - accuracy: 0.7878\n",
      "Epoch 3/3\n",
      "150/150 [==============================] - 0s 652us/step - loss: 0.3887 - accuracy: 0.8352\n",
      "165/165 [==============================] - 0s 494us/step\n",
      "Epoch 1/3\n",
      "150/150 [==============================] - 0s 638us/step - loss: 0.6403 - accuracy: 0.7647\n",
      "Epoch 2/3\n",
      "150/150 [==============================] - 0s 672us/step - loss: 0.5060 - accuracy: 0.7689\n",
      "Epoch 3/3\n",
      "150/150 [==============================] - 0s 658us/step - loss: 0.4120 - accuracy: 0.8114\n",
      "165/165 [==============================] - 0s 464us/step\n",
      "Epoch 1/3\n",
      "150/150 [==============================] - 0s 611us/step - loss: 0.6386 - accuracy: 0.7604\n",
      "Epoch 2/3\n",
      "150/150 [==============================] - 0s 631us/step - loss: 0.5097 - accuracy: 0.7661\n",
      "Epoch 3/3\n",
      "150/150 [==============================] - 0s 638us/step - loss: 0.4294 - accuracy: 0.7973\n",
      "165/165 [==============================] - 0s 470us/step\n",
      "Epoch 1/3\n",
      "300/300 [==============================] - 1s 714us/step - loss: 0.5574 - accuracy: 0.7753\n",
      "Epoch 2/3\n",
      "300/300 [==============================] - 0s 700us/step - loss: 0.3424 - accuracy: 0.8608\n",
      "Epoch 3/3\n",
      "300/300 [==============================] - 0s 683us/step - loss: 0.2576 - accuracy: 0.9135\n"
     ]
    }
   ],
   "source": [
    "grid_search = grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "fd77b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "3b22449d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 35, 'epochs': 3, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "e18085bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8276059657621859"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f9a6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
